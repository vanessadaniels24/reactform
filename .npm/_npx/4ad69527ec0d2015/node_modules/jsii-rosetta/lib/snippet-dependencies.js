"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.prepareDependencyDirectory = exports.validateAvailableDependencies = exports.collectDependencies = void 0;
const cp = require("child_process");
const fastGlob = require("fast-glob");
const fs_1 = require("fs");
const fs = require("fs");
const os = require("os");
const path = require("path");
const semver = require("semver");
const semver_intersect_1 = require("semver-intersect");
const find_utils_1 = require("./find-utils");
const logging = require("./logging");
const util_1 = require("./util");
/**
 * Collect the dependencies of a bunch of snippets together in one declaration
 *
 * We assume here the dependencies will not conflict.
 */
function collectDependencies(snippets) {
    const ret = {};
    for (const snippet of snippets) {
        for (const [name, source] of Object.entries(snippet.compilationDependencies ?? {})) {
            ret[name] = resolveConflict(name, source, ret[name]);
        }
    }
    return ret;
}
exports.collectDependencies = collectDependencies;
function resolveConflict(name, a, b) {
    if (!b) {
        return a;
    }
    if (a.type === 'concrete' && b.type === 'concrete') {
        if (b.resolvedDirectory !== a.resolvedDirectory) {
            throw new Error(`Dependency conflict: ${name} can be either ${a.resolvedDirectory} or ${b.resolvedDirectory}`);
        }
        return a;
    }
    if (a.type === 'symbolic' && b.type === 'symbolic') {
        // Intersect the ranges
        return {
            type: 'symbolic',
            versionRange: (0, semver_intersect_1.intersect)(a.versionRange, b.versionRange),
        };
    }
    if (a.type === 'concrete' && b.type === 'symbolic') {
        const concreteVersion = JSON.parse(fs.readFileSync(path.join(a.resolvedDirectory, 'package.json'), 'utf-8')).version;
        if (!semver.satisfies(concreteVersion, b.versionRange)) {
            throw new Error(`Dependency conflict: ${name} expected to match ${b.versionRange} but found ${concreteVersion} at ${a.resolvedDirectory}`);
        }
        return a;
    }
    if (a.type === 'symbolic' && b.type === 'concrete') {
        // Reverse roles so we fall into the previous case
        return resolveConflict(name, b, a);
    }
    throw new Error('Cases should have been exhaustive');
}
/**
 * Check that the directory we were given has all the necessary dependencies in it
 *
 * It's a warning if this is not true, not an error.
 */
async function validateAvailableDependencies(directory, deps) {
    const failures = await Promise.all(Object.entries(deps).flatMap(async ([name, _dep]) => {
        try {
            await (0, find_utils_1.findDependencyDirectory)(name, directory);
            return [];
        }
        catch {
            return [name];
        }
    }));
    if (failures.length > 0) {
        logging.warn(`${directory}: packages necessary to compile examples missing from supplied directory: ${failures.join(', ')}`);
    }
}
exports.validateAvailableDependencies = validateAvailableDependencies;
/**
 * Prepare a temporary directory with symlinks to all the dependencies we need.
 *
 * - Symlinks the concrete dependencies
 * - Tries to first find the symbolic dependencies in a potential monorepo that might be present
 *   (try both `lerna` and `yarn` monorepos).
 * - Installs the remaining symbolic dependencies using 'npm'.
 */
async function prepareDependencyDirectory(deps) {
    const concreteDirs = Object.values(deps)
        .filter(isConcrete)
        .map((x) => x.resolvedDirectory);
    const monorepoPackages = await scanMonoRepos(concreteDirs);
    const tmpDir = await fs_1.promises.mkdtemp(path.join(os.tmpdir(), 'rosetta'));
    logging.info(`Preparing dependency closure at ${tmpDir}`);
    // Resolved symbolic packages against monorepo
    const resolvedDeps = (0, util_1.mkDict)(Object.entries(deps).map(([name, dep]) => [
        name,
        dep.type === 'concrete'
            ? dep
            : (monorepoPackages[name]
                ? { type: 'concrete', resolvedDirectory: monorepoPackages[name] }
                : dep),
    ]));
    // Use 'npm install' only for the symbolic packages. For the concrete packages,
    // npm is going to try and find transitive dependencies as well and it won't know
    // about monorepos.
    const symbolicInstalls = Object.entries(resolvedDeps).flatMap(([name, dep]) => isSymbolic(dep) ? [`${name}@${dep.versionRange}`] : []);
    const linkedInstalls = (0, util_1.mkDict)(Object.entries(resolvedDeps).flatMap(([name, dep]) => isConcrete(dep) ? [[name, dep.resolvedDirectory]] : []));
    // Run 'npm install' on it
    if (symbolicInstalls.length > 0) {
        logging.debug(`Installing example dependencies: ${symbolicInstalls.join(' ')}`);
        cp.execSync(`npm install ${symbolicInstalls.join(' ')}`, { cwd: tmpDir, encoding: 'utf-8' });
    }
    // Symlink the rest
    if (Object.keys(linkedInstalls).length > 0) {
        logging.debug(`Symlinking example dependencies: ${Object.values(linkedInstalls).join(' ')}`);
        const modDir = path.join(tmpDir, 'node_modules');
        await Promise.all(Object.entries(linkedInstalls).map(async ([name, source]) => {
            const target = path.join(modDir, name);
            if (!(await (0, util_1.pathExists)(target))) {
                // Package could be namespaced, so ensure the namespace dir exists
                await fs_1.promises.mkdir(path.dirname(target), { recursive: true });
                await fs_1.promises.symlink(source, target, 'dir');
            }
        }));
    }
    return tmpDir;
}
exports.prepareDependencyDirectory = prepareDependencyDirectory;
/**
 * Map package name to directory
 */
async function scanMonoRepos(startingDirs) {
    const globs = new Set();
    for (const dir of startingDirs) {
        // eslint-disable-next-line no-await-in-loop
        setExtend(globs, await findMonoRepoGlobs(dir));
    }
    if (globs.size === 0) {
        return {};
    }
    logging.debug(`Monorepo package sources: ${Array.from(globs).join(', ')}`);
    const packageDirectories = await fastGlob(Array.from(globs).map(windowsToUnix), { onlyDirectories: true });
    const results = (0, util_1.mkDict)((await Promise.all(packageDirectories.map(async (directory) => {
        const pjLocation = path.join(directory, 'package.json');
        return (await (0, util_1.pathExists)(pjLocation))
            ? [[JSON.parse(await fs_1.promises.readFile(pjLocation, 'utf-8')).name, directory]]
            : [];
    }))).flat());
    logging.debug(`Found ${Object.keys(results).length} packages in monorepo: ${(0, util_1.formatList)(Object.keys(results))}`);
    return results;
}
async function findMonoRepoGlobs(startingDir) {
    const ret = new Set();
    // Lerna monorepo
    const lernaJsonDir = await (0, find_utils_1.findUp)(startingDir, async (dir) => (0, util_1.pathExists)(path.join(dir, 'lerna.json')));
    if (lernaJsonDir) {
        const lernaJson = JSON.parse(await fs_1.promises.readFile(path.join(lernaJsonDir, 'lerna.json'), 'utf-8'));
        for (const glob of lernaJson?.packages ?? []) {
            ret.add(path.join(lernaJsonDir, glob));
        }
    }
    // Yarn monorepo
    const yarnWsDir = await (0, find_utils_1.findUp)(startingDir, async (dir) => (await (0, util_1.pathExists)(path.join(dir, 'package.json'))) &&
        JSON.parse(await fs_1.promises.readFile(path.join(dir, 'package.json'), 'utf-8'))?.workspaces !== undefined);
    if (yarnWsDir) {
        const yarnWs = JSON.parse(await fs_1.promises.readFile(path.join(yarnWsDir, 'package.json'), 'utf-8'));
        for (const glob of yarnWs.workspaces?.packages ?? []) {
            ret.add(path.join(yarnWsDir, glob));
        }
    }
    return ret;
}
function isSymbolic(x) {
    return x.type === 'symbolic';
}
function isConcrete(x) {
    return x.type === 'concrete';
}
function setExtend(xs, ys) {
    for (const y of ys) {
        xs.add(y);
    }
    return xs;
}
/**
 * Necessary for fastGlob
 */
function windowsToUnix(x) {
    return x.replace(/\\/g, '/');
}
//# sourceMappingURL=snippet-dependencies.js.map